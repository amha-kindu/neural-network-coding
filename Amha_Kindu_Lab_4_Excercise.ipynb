{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUH/rGB/Awit0Sqd+/U242",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amha-kindu/neural-network-coding/blob/main/Amha_Kindu_Lab_4_Excercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "WsokQa_mZYUW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "k1c--UvVYsAO"
      },
      "outputs": [],
      "source": [
        "class DenseLayer:\n",
        "  activations = {\n",
        "      \"relu\": lambda x: torch.max(torch.tensor(0, dtype=x.dtype), x),\n",
        "      \"softmax\": lambda x, dim=1: torch.exp(x - torch.max(x, dim=dim, keepdim=True).values) / torch.exp(x - torch.max(x, dim=dim, keepdim=True).values).sum(dim=dim, keepdim=True),\n",
        "      \"sigmoid\": lambda x: 1 / (1 + torch.exp(-x))\n",
        "  }\n",
        "  def __init__(self, features=1, neurons=1, activation=\"relu\"):\n",
        "    self.weights = torch.rand(features, neurons)\n",
        "    self.bias = torch.rand((1, neurons))\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    activation = DenseLayer.activations[self.activation]\n",
        "    return activation(torch.matmul(inputs, self.weights) + self.bias)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layers: list[DenseLayer]):\n",
        "        self.layers = layers\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = inputs\n",
        "        for layer in self.layers:\n",
        "            output = layer.forward(output)\n",
        "        return output\n",
        "\n",
        "    def mse_loss(self, prediction, target):\n",
        "        return torch.mean((prediction - target)**2)\n",
        "\n",
        "    def backward(self, inputs, targets, learning_rate=0.01):\n",
        "        predictions = self.forward(inputs)\n",
        "\n",
        "        loss = self.mse_loss(predictions, targets)\n",
        "\n",
        "        loss_grad = 2 * (predictions - targets) / len(targets)  # Gradient of MSE loss\n",
        "\n",
        "        for i in reversed(range(len(self.layers))):\n",
        "            layer = self.layers[i]\n",
        "\n",
        "            layer_grad = torch.matmul(inputs, loss_grad)\n",
        "            bias_grad = torch.sum(loss_grad, dim=0, keepdim=True)\n",
        "\n",
        "            layer.linear.weight -= learning_rate * layer_grad\n",
        "            layer.linear.bias -= learning_rate * bias_grad\n",
        "\n",
        "            loss_grad = torch.matmul(loss_grad, layer.linear.weight.t())\n",
        "\n",
        "    def train(self, inputs, targets, learning_rate=0.01, num_epochs=1000):\n",
        "        for epoch in range(num_epochs):\n",
        "            self.backward(inputs, targets, learning_rate)\n",
        "            if (epoch + 1) % 100 == 0:\n",
        "                predictions = self.forward(inputs)\n",
        "                loss = self.mse_loss(predictions, targets)\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "    def cross_entropy_loss(self, prediction, target):\n",
        "      return -torch.sum(prediction * torch.log(target))\n",
        "\n",
        "    def accuracy(self, prediction, target):\n",
        "      _, predicted_classes = torch.max(prediction, 1)\n",
        "      _, true_classes = torch.max(target, 1)\n",
        "\n",
        "      correct_predictions = (predicted_classes == true_classes).sum().item()\n",
        "      return correct_predictions / target.size(0)"
      ],
      "metadata": {
        "id": "iUUNdjgaZ4aa"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork([\n",
        "    DenseLayer(4, 18, \"relu\"),\n",
        "    DenseLayer(18, 18, \"sigmoid\"),\n",
        "    DenseLayer(18, 18, \"relu\"),\n",
        "    DenseLayer(18, 1, \"softmax\")\n",
        "])\n",
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47sq02hCbAUj",
        "outputId": "c073dd4b-6ff3-4905-8244-a9878f02563b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.DenseLayer at 0x7c84c43cebf0>,\n",
              " <__main__.DenseLayer at 0x7c84c43cf100>,\n",
              " <__main__.DenseLayer at 0x7c84c4256800>,\n",
              " <__main__.DenseLayer at 0x7c84c4254f70>]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1, 4)\n",
        "target = torch.rand(1, 3)\n",
        "print(f\"Input: {x}\\nTarget: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZKkyi0PbvKJ",
        "outputId": "2561d9ff-bb0f-4023-820a-564999980ec4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([[0.0149, 0.0180, 0.1160, 0.9163]])\n",
            "Target: tensor([[0.6785, 0.0093, 0.8334]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.forward(x)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEXd1pvHb7uO",
        "outputId": "8f44531c-4bff-4199-c267-01f9771f1317"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.cross_entropy_loss(prediction, target)\n",
        "accuracy = model.accuracy(prediction, target)\n",
        "print(f\"Cross-entropy loss: {loss}\\nAccuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwfFcS_Mwh_x",
        "outputId": "833e97ff-6db8-40bb-d312-300855ec3b01"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-entropy loss: 5.246840000152588\n",
            "Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Input (x)\n",
        "test_input = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "\n",
        "# Expected Output (f(x))\n",
        "test_output = test_input.pow(2) + 3 * test_input"
      ],
      "metadata": {
        "id": "U10kcNCZ44NS"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(test_input, test_output, learning_rate=0.01, num_epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "tyxLCXjp5PJQ",
        "outputId": "d7c419d9-5d6a-43ac-c49e-5871a05b6ce1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-9a75c1906452>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-3c050567deb0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, targets, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-3c050567deb0>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, inputs, targets, learning_rate)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# if hasattr(layer, 'linear'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Gradient for weights and biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mlayer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mbias_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x4 and 1x4)"
          ]
        }
      ]
    }
  ]
}